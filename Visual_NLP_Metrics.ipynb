{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VnRLc8L8Dj-v"
   },
   "outputs": [],
   "source": [
    "# Python Script used to extract the Ground truth, dicom files \n",
    "# Requires a Zip File in same directory with name \"dicom_files.zip\"\n",
    "!python prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u9IS7jCHICyo"
   },
   "outputs": [],
   "source": [
    "def calculate_precision(gt, pred):\n",
    "    tp = [i for i in pred if i in gt]\n",
    "    try:\n",
    "        precision = len(tp) / len(pred)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(gt, pred):\n",
    "    tp = [i for i in pred if i in gt]\n",
    "    try:\n",
    "        recall = len(tp) / len(gt)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "\n",
    "    return recall\n",
    "\n",
    "def calculate_metrics(gt_path, df_path, save_result_path, ner_chunk=\"merged_ner_chunk\"):\n",
    "\n",
    "    \"\"\"\n",
    "    gt_path - The location of json file containing ground truth. Generate using prepare_data.py \n",
    "    df_path - The location of parquet file containing result from Visual NLP pipeline.\n",
    "    save_result_path - The location of the output json file containing result \n",
    "    ner_chunk - The column name containing final chunks used for metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    total_precision = 0.0\n",
    "    total_recall = 0.0\n",
    "\n",
    "    with open(gt_path, \"r\") as file_in:\n",
    "        gt = json.loads(file_in.read())\n",
    "\n",
    "    df = spark.read.format(\"parquet\").load(df_path).select(\"path\", ner_chunk)\n",
    "\n",
    "    total_files = df.count()\n",
    "    print(f\"Total Files : {total_files}\")\n",
    "\n",
    "    save_result = []\n",
    "\n",
    "    for item_row in df.toLocalIterator():\n",
    "        data = item_row.asDict()\n",
    "\n",
    "        img_path = os.path.basename(data[\"path\"])\n",
    "        chunks = data[ner_chunk]\n",
    "\n",
    "        collect_pred = []\n",
    "        for chunk in chunks:\n",
    "            pred = chunk.asDict()[\"result\"].strip().lower()\n",
    "            collect_pred.append(pred)\n",
    "\n",
    "        lowered_gt = [i.lower() for i in gt[img_path]]\n",
    "\n",
    "        precision = calculate_precision(lowered_gt, collect_pred)\n",
    "        recall = calculate_recall(lowered_gt, collect_pred)\n",
    "\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "\n",
    "        save_result.append({\"Filename\" : img_path,\n",
    "                             \"Ground Truth\" : lowered_gt,\n",
    "                             \"Predicted PHI\" : collect_pred,\n",
    "                             \"Precision\" : precision,\n",
    "                             \"Recall\" : recall})\n",
    "\n",
    "    total_precision = round(total_precision / total_files, 1)\n",
    "    total_recall = round(total_recall / total_files, 1)\n",
    "    f1_score = round(2 * ((total_precision * total_recall) / (total_precision + total_recall)), 1)\n",
    "\n",
    "    print(f\"Precision : {total_precision}\")\n",
    "    print(f\"Recall : {total_recall}\")\n",
    "    print(f\"F1-Score : {f1_score}\")\n",
    "\n",
    "    with open(save_result_path, \"w\") as result_file_out:\n",
    "        json.dump(save_result, result_file_out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "C-ickKGnDqJu",
    "outputId": "01c3e7e8-ed68-4b49-af6f-48305192b8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.0\n",
      "Spark NLP version: 5.5.2\n",
      "Spark NLP for Healthcare version: 5.5.2\n",
      "Spark OCR version: 5.5.1rc1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cce70a137807:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark OCR</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7e4732767410>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparkocr import start\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"./creds.json\", \"r\") as creds_in:\n",
    "    creds = json.loads(creds_in.read())[\"Credentials\"]\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = creds[\"AccessKeyId\"]\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = creds[\"SecretAccessKey\"]\n",
    "os.environ['AWS_SESSION_TOKEN'] = creds[\"SessionToken\"]\n",
    "os.environ['SPARK_OCR_LICENSE'] = creds[\"SPARK_OCR_LICENSE\"]\n",
    "\n",
    "colab_max = {\n",
    "    \"spark.driver.memory\": \"10g\",\n",
    "    \"spark.executor.memory\": \"12g\",\n",
    "    \"spark.executor.memoryOverhead\": \"3g\",\n",
    "    \"spark.driver.memoryOverhead\": \"2g\",\n",
    "    \"spark.extraListeners\": \"com.johnsnowlabs.license.LicenseLifeCycleManager\",\n",
    "    \"spark.cores.max\": \"12\",\n",
    "    \"spark.executor.cores\": \"4\"\n",
    "}\n",
    "\n",
    "spark = start(jar_path=\"./\",\n",
    "              nlp_secret=\"5.5.2.PR-2579.6fce19f4d0e8cce1d61a808968c833c932bf2dd1\",\n",
    "              nlp_internal=True,\n",
    "              nlp_jsl=True,\n",
    "              nlp_version=\"5.5.2\",\n",
    "              extra_conf=colab_max,\n",
    "              use_gpu=True)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xX1VUITJEFMI",
    "outputId": "184f90b4-15e1-4019-cfc4-f7465f90780c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version: 5.5.2\n",
      "Spark NLP internal version: 5.5.2\n",
      "Spark OCR version: 5.5.1rc1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "import sparkocr\n",
    "from sparkocr.transformers import *\n",
    "from sparkocr.utils import *\n",
    "from sparkocr.enums import *\n",
    "\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "print(f\"Spark NLP version: {sparknlp.version()}\")\n",
    "print(f\"Spark NLP internal version: {sparknlp_jsl.version()}\")\n",
    "print(f\"Spark OCR version: {sparkocr.version()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9UJZH2S4x3Wh"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./results/\", exist_ok=True)\n",
    "os.makedirs(\"./results/deid_image_result/\", exist_ok=True)\n",
    "os.makedirs(\"./results/ner_result/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Hy0zu9EFDUh",
    "outputId": "84dcdb06-a305-449d-b418-4c859e2d64fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 354.6 KB\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_deid_large download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "dicom_to_image = DicomToImageV3() \\\n",
    "    .setInputCols([\"content\"]) \\\n",
    "    .setOutputCol(\"image_raw\") \\\n",
    "    .setKeepInput(False)\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document_raw\") \\\n",
    "    .setCleanupMode(\"shrink\")\n",
    "\n",
    "cleanUpPatterns = [\"<[^>]*>\", r\"\\^ ?\", r\"\\^\"]\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "  .setInputCols(\"document_raw\") \\\n",
    "  .setOutputCol(\"document\") \\\n",
    "  .setAction(\"clean\") \\\n",
    "  .setPatterns(cleanUpPatterns) \\\n",
    "  .setReplacement(\" \") \\\n",
    "  .setPolicy(\"pretty_all\")\n",
    "\n",
    "sentencerDL = SentenceDetectorDLModel\\\n",
    "    .pretrained(\"sentence_detector_dl\", \"en\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = MedicalNerModel.pretrained(\"ner_deid_large\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner_subentity\")\n",
    "\n",
    "regex_matcher = RegexMatcher()\\\n",
    "    .setInputCols(\"sentence\")\\\n",
    "    .setOutputCol(\"regex\")\\\n",
    "    .setRules([\"[0-9]{4} (JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC) [0-9]{1,2};DATE\",\n",
    "               \"(0[1-9]|1[0-2])/(0[1-9]|[12][0-9]|3[01])/\\d{4};DATENUM\",\n",
    "               \"(?:\\s[MF]|\\b[MF])(?:\\s|\\b|$);GENDER\",\n",
    "               \"(?<!\\d)\\d{9,10}(?!\\d);ID\"])\\\n",
    "    .setDelimiter(\";\")\n",
    "\n",
    "chunkConverter = ChunkConverter()\\\n",
    "    .setInputCols(\"regex\")\\\n",
    "    .setOutputCol(\"regex_chunks\")\n",
    "\n",
    "custom_ner_converter_internal = NerConverterInternalModel() \\\n",
    "    .setInputCols([\"sentence\",\"token\", \"ner_subentity\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\") \\\n",
    "    .setThreshold(0.4) \\\n",
    "    .setWhiteList(['NAME', 'AGE', 'LOCATION', 'PERSON', 'DOCTOR', 'PATIENT'])\n",
    "\n",
    "chunk_merger = ChunkMergeApproach()\\\n",
    "    .setInputCols('regex_chunks', \"ner_chunk\")\\\n",
    "    .setOutputCol('merged_ner_chunk')\\\n",
    "    .setMergeOverlapping(True)\n",
    "\n",
    "base_stages = [\n",
    "    dicom_to_image,\n",
    "    documentAssembler,\n",
    "    documentNormalizer,\n",
    "    sentencerDL,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    regex_matcher,\n",
    "    chunkConverter,\n",
    "    custom_ner_converter_internal,\n",
    "    chunk_merger\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQl1_9RCFHhO",
    "outputId": "7abee3f4-380d-4375-b8c5-1c8e5a7971a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_text_detector_mem_opt download started this may take some time.\n",
      "Approximate size to download 77.5 MB\n"
     ]
    }
   ],
   "source": [
    "text_detector = ImageTextDetector.pretrained(\"image_text_detector_mem_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text_regions\") \\\n",
    "    .setScoreThreshold(0.7) \\\n",
    "    .setLinkThreshold(0.5) \\\n",
    "    .setWithRefiner(True) \\\n",
    "    .setTextThreshold(0.4) \\\n",
    "    .setSizeThreshold(-1) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setWidth(0)\n",
    "\n",
    "ocr = ImageToTextV2.pretrained(\"ocr_base_printed_v2_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setRegionsColumn(\"text_regions\") \\\n",
    "    .setInputCols([\"image_raw\"]) \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setOutputFormat(\"text_with_positions\") \\\n",
    "    .setGroupImages(False) \\\n",
    "    .setKeepInput(False) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setUseCaching(True) \\\n",
    "    .setBatchSize(4)\n",
    "\n",
    "new_stages = base_stages.copy()\n",
    "\n",
    "new_stages.insert(1,text_detector)\n",
    "new_stages.insert(2,ocr)\n",
    "\n",
    "detector_v2_base_v2 = Pipeline(stages=new_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1J-Cnx-HH3cD",
    "outputId": "19e4c29e-435e-4406-957c-58cb4373e8a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 3.63\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"binaryFile\").load(\"./dicom_files/*.dcm\")\n",
    "\n",
    "result_base = detector_v2_base_v2.fit(df).transform(df)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_base.write.format(\"parquet\").mode(\"overwrite\").save(\"./result_base/\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time Taken : {round((end - start) / df.count(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4uZvjoYIAaR",
    "outputId": "301999ef-6da6-4824-cf88-a87731f405eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files : 15\n",
      "Precision : 0.8\n",
      "Recall : 0.8\n",
      "F1-Score : 0.8\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"./gt_ocr.json\"\n",
    "df_path = \"./result_base/\"\n",
    "result_path = \"./results/ner_result/result_v2_base.json\"\n",
    "\n",
    "calculate_metrics(gt_path, df_path, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wK8XlQmhKkAC",
    "outputId": "6074e372-5ce2-47bf-8d23-0bff60c67901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_text_detector_mem_opt download started this may take some time.\n",
      "Approximate size to download 77.5 MB\n"
     ]
    }
   ],
   "source": [
    "text_detector = ImageTextDetector.pretrained(\"image_text_detector_mem_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text_regions\") \\\n",
    "    .setScoreThreshold(0.7) \\\n",
    "    .setLinkThreshold(0.5) \\\n",
    "    .setWithRefiner(True) \\\n",
    "    .setTextThreshold(0.4) \\\n",
    "    .setSizeThreshold(-1) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setWidth(0)\n",
    "\n",
    "ocr = ImageToTextV2.pretrained(\"ocr_large_printed_v2_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setRegionsColumn(\"text_regions\") \\\n",
    "    .setInputCols([\"image_raw\"]) \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setOutputFormat(\"text_with_positions\") \\\n",
    "    .setGroupImages(False) \\\n",
    "    .setKeepInput(False) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setUseCaching(True) \\\n",
    "    .setBatchSize(4)\n",
    "\n",
    "new_stages = base_stages.copy()\n",
    "\n",
    "new_stages.insert(1,text_detector)\n",
    "new_stages.insert(2,ocr)\n",
    "\n",
    "detector_v2_large_v2 = Pipeline(stages=new_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FB0pzySUca6B",
    "outputId": "4ad067b8-d57e-4cc7-9fd6-8db01a5a038d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 4.06\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"binaryFile\").load(\"./dicom_files/*.dcm\")\n",
    "\n",
    "result_large = detector_v2_large_v2.fit(df).transform(df)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_large.write.format(\"parquet\").mode(\"overwrite\").save(\"./result_large/\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time Taken : {round((end - start) / df.count(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7AzRUGKrvVS",
    "outputId": "fcef5dc3-5aef-4758-8fd3-c58bc1e8dff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files : 15\n",
      "Precision : 0.9\n",
      "Recall : 0.8\n",
      "F1-Score : 0.8\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"./gt_ocr.json\"\n",
    "df_path = \"./result_large/\"\n",
    "result_path = \"./results/ner_result/result_v2_large.json\"\n",
    "\n",
    "calculate_metrics(gt_path, df_path, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOe-r25_cqqr",
    "outputId": "19fdcfad-8756-4338-b673-eae45a4a7024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_text_detector_mem_opt download started this may take some time.\n",
      "Approximate size to download 77.5 MB\n"
     ]
    }
   ],
   "source": [
    "text_detector = ImageTextDetector.pretrained(\"image_text_detector_mem_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text_regions\") \\\n",
    "    .setScoreThreshold(0.7) \\\n",
    "    .setLinkThreshold(0.5) \\\n",
    "    .setWithRefiner(True) \\\n",
    "    .setTextThreshold(0.4) \\\n",
    "    .setSizeThreshold(-1) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setWidth(0)\n",
    "\n",
    "ocr = ImageToTextV3() \\\n",
    "    .setInputCols([\"image_raw\", \"text_regions\"]) \\\n",
    "    .setOutputCol(\"text\")\n",
    "\n",
    "new_stages = base_stages.copy()\n",
    "\n",
    "new_stages.insert(1,text_detector)\n",
    "new_stages.insert(2,ocr)\n",
    "\n",
    "detector_v3 = Pipeline(stages=new_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yt6tL7YXeu9V",
    "outputId": "0549e73b-3a52-458e-e700-5aff35d667e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 0.68\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"binaryFile\").load(\"./dicom_files/*.dcm\")\n",
    "\n",
    "result_v3 = detector_v3.fit(df).transform(df)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_v3.write.format(\"parquet\").mode(\"overwrite\").save(\"./result_v3/\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time Taken : {round((end - start) / df.count(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ys68noy-klzD",
    "outputId": "45aca704-13d6-4d01-dc87-2a165d048d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files : 15\n",
      "Precision : 0.7\n",
      "Recall : 0.4\n",
      "F1-Score : 0.5\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"./gt_ocr.json\"\n",
    "df_path = \"./result_v3/\"\n",
    "result_path = \"./results/ner_result/result_v3.json\"\n",
    "\n",
    "calculate_metrics(gt_path, df_path, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "4eOxL_4rk3L5"
   },
   "outputs": [],
   "source": [
    "ocr = ImageToText() \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setIgnoreResolution(False) \\\n",
    "    .setPageIteratorLevel(PageIteratorLevel.SYMBOL) \\\n",
    "    .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) \\\n",
    "    .setWithSpaces(True) \\\n",
    "    .setConfidenceThreshold(70)\n",
    "\n",
    "new_stages = base_stages.copy()\n",
    "\n",
    "new_stages.insert(1,ocr)\n",
    "\n",
    "tesseract_pipe = Pipeline(stages=new_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyk2m1HK86m_",
    "outputId": "3371df9c-bcf8-4c1d-c6e4-0ba14a5c748b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 0.31\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"binaryFile\").load(\"./dicom_files/*.dcm\")\n",
    "\n",
    "result_tesseract = tesseract_pipe.fit(df).transform(df)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_tesseract.write.format(\"parquet\").mode(\"overwrite\").save(\"./result_tesseract/\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time Taken : {round((end - start) / df.count(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbhCP7wU9AfS",
    "outputId": "0bf1c543-1b04-4623-9e10-c98cb4cc6cf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files : 15\n",
      "Precision : 0.5\n",
      "Recall : 0.3\n",
      "F1-Score : 0.4\n"
     ]
    }
   ],
   "source": [
    "gt_path = \"./gt_ocr.json\"\n",
    "df_path = \"./result_tesseract/\"\n",
    "result_path = \"./results/ner_result/result_tesseract.json\"\n",
    "\n",
    "calculate_metrics(gt_path, df_path, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3k93c_N9XKM",
    "outputId": "2e0f27f2-df4d-499e-c3db-ebc7a81f571f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 354.6 KB\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_deid_large download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "dicom_to_image = DicomToImageV3() \\\n",
    "    .setInputCols([\"content\"]) \\\n",
    "    .setOutputCol(\"image_raw\") \\\n",
    "    .setKeepInput(False)\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document_raw\") \\\n",
    "    .setCleanupMode(\"shrink\")\n",
    "\n",
    "cleanUpPatterns = [\"<[^>]*>\", r\"\\^ ?\", r\"\\^\"]\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "  .setInputCols(\"document_raw\") \\\n",
    "  .setOutputCol(\"document\") \\\n",
    "  .setAction(\"clean\") \\\n",
    "  .setPatterns(cleanUpPatterns) \\\n",
    "  .setReplacement(\" \") \\\n",
    "  .setPolicy(\"pretty_all\")\n",
    "\n",
    "sentencerDL = SentenceDetectorDLModel\\\n",
    "    .pretrained(\"sentence_detector_dl\", \"en\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = MedicalNerModel.pretrained(\"ner_deid_large\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner_subentity\")\n",
    "\n",
    "regex_matcher = RegexMatcher()\\\n",
    "    .setInputCols(\"sentence\")\\\n",
    "    .setOutputCol(\"regex\")\\\n",
    "    .setRules([\"[0-9]{4} (JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC) [0-9]{1,2};DATE\",\n",
    "               \"(0[1-9]|1[0-2])/(0[1-9]|[12][0-9]|3[01])/\\d{4};DATENUM\",\n",
    "               \"(?:\\s[MF]|\\b[MF])(?:\\s|\\b|$);GENDER\",\n",
    "               \"(?<!\\d)\\d{9,10}(?!\\d);ID\"])\\\n",
    "    .setDelimiter(\";\")\n",
    "\n",
    "chunkConverter = ChunkConverter()\\\n",
    "    .setInputCols(\"regex\")\\\n",
    "    .setOutputCol(\"regex_chunks\")\n",
    "\n",
    "custom_ner_converter_internal = NerConverterInternalModel() \\\n",
    "    .setInputCols([\"sentence\",\"token\", \"ner_subentity\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\") \\\n",
    "    .setThreshold(0.4) \\\n",
    "    .setWhiteList(['NAME', 'AGE', 'LOCATION', 'PERSON', 'DOCTOR', 'PATIENT'])\n",
    "\n",
    "chunk_merger = ChunkMergeApproach()\\\n",
    "    .setInputCols('regex_chunks', \"ner_chunk\")\\\n",
    "    .setOutputCol('merged_ner_chunk')\\\n",
    "    .setMergeOverlapping(True)\n",
    "\n",
    "position_finder = PositionFinder() \\\n",
    "    .setInputCols(\"merged_ner_chunk\") \\\n",
    "    .setOutputCol(\"coordinates\") \\\n",
    "    .setPageMatrixCol(\"positions\") \\\n",
    "    .setOcrScaleFactor(0.9)\n",
    "\n",
    "draw_regions = DicomDrawRegions() \\\n",
    "    .setInputCol(\"path\") \\\n",
    "    .setInputRegionsCol(\"coordinates\") \\\n",
    "    .setOutputCol(\"dicom_cleaned\") \\\n",
    "    .setAggCols([\"path\"]) \\\n",
    "    .setKeepInput(True)\n",
    "\n",
    "base_stages = [\n",
    "    dicom_to_image,\n",
    "    documentAssembler,\n",
    "    documentNormalizer,\n",
    "    sentencerDL,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    regex_matcher,\n",
    "    chunkConverter,\n",
    "    custom_ner_converter_internal,\n",
    "    chunk_merger,\n",
    "    position_finder,\n",
    "    draw_regions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nS2_87lX-sZQ",
    "outputId": "98228ed2-6c66-4350-b537-ee98660517c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_text_detector_mem_opt download started this may take some time.\n",
      "Approximate size to download 77.5 MB\n"
     ]
    }
   ],
   "source": [
    "text_detector = ImageTextDetector.pretrained(\"image_text_detector_mem_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text_regions\") \\\n",
    "    .setScoreThreshold(0.7) \\\n",
    "    .setLinkThreshold(0.5) \\\n",
    "    .setWithRefiner(True) \\\n",
    "    .setTextThreshold(0.4) \\\n",
    "    .setSizeThreshold(-1) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setWidth(0)\n",
    "\n",
    "ocr = ImageToTextV2.pretrained(\"ocr_large_printed_v2_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setRegionsColumn(\"text_regions\") \\\n",
    "    .setInputCols([\"image_raw\"]) \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setOutputFormat(\"text_with_positions\") \\\n",
    "    .setGroupImages(False) \\\n",
    "    .setKeepInput(False) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setUseCaching(True) \\\n",
    "    .setBatchSize(4)\n",
    "\n",
    "new_stages = base_stages.copy()\n",
    "\n",
    "new_stages.insert(1,text_detector)\n",
    "new_stages.insert(2,ocr)\n",
    "\n",
    "detector_v2_large_v2 = Pipeline(stages=new_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTxBX4AR-0qr",
    "outputId": "442f8596-6998-4f33-c7e6-72c167078084"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"binaryFile\").load(\"./dicom_files/*.dcm\")\n",
    "\n",
    "result_large = detector_v2_large_v2.fit(df).transform(df)\n",
    "\n",
    "result_base.write.format(\"parquet\").mode(\"overwrite\").save(\"./result_large_dicom/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "y5UuzI20-9tO"
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"./result_large_dicom/\")\n",
    "\n",
    "for row in df.select(\"path\", \"dicom_cleaned\").toLocalIterator():\n",
    "    data = row.asDict()\n",
    "    dicom_file = data[\"dicom_cleaned\"]\n",
    "    path = data[\"path\"]\n",
    "\n",
    "    base_name = os.path.basename(path).replace(\".dcm\", \".jpg\")\n",
    "\n",
    "    ds = pydicom.dcmread(io.BytesIO(dicom_file))\n",
    "    image = Image.fromarray(ds.pixel_array).convert(\"L\")\n",
    "\n",
    "    file_out = os.path.join(\"./results/deid_image_result/\", base_name)\n",
    "    image.save(file_out)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
